{description: open_instruct_eval_tydiqa_goldp_1shot_test_tulu_7b_01262024, tasks: [
    {arguments: ["\n            python -m eval.tydiqa.run_eval             --data_dir\
          \ /data/tydiqa/             --n_shot 1             --max_num_examples_per_lang\
          \ 100             --max_context_length 512             --save_dir /output/\
          \             --use_vllm             --model /model             --tokenizer_name_or_path\
          \ /model             --use_chat_format             --chat_formatting_function\
          \ eval.templates.create_prompt_with_tulu_chat_format\n        "], command: [
        /bin/sh, -c], context: {cluster: ai2/allennlp-cirrascale, priority: high},
      datasets: [{mountPath: /data/, source: {beaker: Yizhongw03/open_instruct_eval_data}},
        {mountPath: /model, source: {beaker: 01HN4NFXMM097JR4GQ5Q0C1GEC}}, {mountPath: /net/nfs.cirrascale,
          source: {hostPath: /net/nfs.cirrascale}}], envVars: [{name: CUDA_DEVICE_ORDER,
          value: PCI_BUS_ID}, {name: TRANSFORMERS_CACHE, value: ./cache/}, {name: WANDB_PROJECT,
          value: open-instruct}, {name: WANDB_WATCH, value: false}, {name: WANDB_LOG_MODEL,
          value: false}, {name: WANDB_DISABLED, value: true}, {name: OPENAI_API_KEY,
          secret: openai_api_key}], image: {beaker: hamishivi/open-instruct}, name: open_instruct_eval_tydiqa_goldp_1shot_test_tulu_7b_01262024,
      resources: {gpuCount: 1}, result: {path: /output}}], version: v2}
