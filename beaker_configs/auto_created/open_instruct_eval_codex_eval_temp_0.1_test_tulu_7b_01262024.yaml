{description: open_instruct_eval_codex_eval_temp_0.1_test_tulu_7b_01262024, tasks: [
    {arguments: ["\n            python -m eval.codex_humaneval.run_eval          \
          \   --data_file /data/codex_humaneval/HumanEval.jsonl.gz             --eval_pass_at_ks\
          \ 1 5 10 20             --unbiased_sampling_size_n 20             --temperature\
          \ 0.1             --save_dir /output/             --use_vllm           \
          \  --model /model             --tokenizer_name_or_path /model\n        "],
      command: [/bin/sh, -c], context: {cluster: ai2/allennlp-cirrascale, priority: high},
      datasets: [{mountPath: /data/, source: {beaker: Yizhongw03/open_instruct_eval_data}},
        {mountPath: /model, source: {beaker: 01HN4NFXMM097JR4GQ5Q0C1GEC}}, {mountPath: /net/nfs.cirrascale,
          source: {hostPath: /net/nfs.cirrascale}}], envVars: [{name: CUDA_DEVICE_ORDER,
          value: PCI_BUS_ID}, {name: TRANSFORMERS_CACHE, value: ./cache/}, {name: WANDB_PROJECT,
          value: open-instruct}, {name: WANDB_WATCH, value: false}, {name: WANDB_LOG_MODEL,
          value: false}, {name: WANDB_DISABLED, value: true}, {name: OPENAI_API_KEY,
          secret: openai_api_key}], image: {beaker: hamishivi/open-instruct}, name: open_instruct_eval_codex_eval_temp_0.1_test_tulu_7b_01262024,
      resources: {gpuCount: 1}, result: {path: /output}}], version: v2}
