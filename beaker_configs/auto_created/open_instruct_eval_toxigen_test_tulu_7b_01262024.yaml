{description: open_instruct_eval_toxigen_test_tulu_7b_01262024, tasks: [{arguments: [
        "\n        python -m eval.toxigen.run_eval             --data_dir /data/toxigen/\
          \             --save_dir /output/             --model_name_or_path /model\
          \             --tokenizer_name_or_path /model             --eval_batch_size\
          \ 32             --use_vllm             --use_chat_format             --chat_formatting_function\
          \ eval.templates.create_prompt_with_tulu_chat_format\n        "], command: [
        /bin/sh, -c], context: {cluster: ai2/allennlp-cirrascale, priority: high},
      datasets: [{mountPath: /data/, source: {beaker: Yizhongw03/open_instruct_eval_data}},
        {mountPath: /model, source: {beaker: 01HN4NFXMM097JR4GQ5Q0C1GEC}}, {mountPath: /net/nfs.cirrascale,
          source: {hostPath: /net/nfs.cirrascale}}], envVars: [{name: CUDA_DEVICE_ORDER,
          value: PCI_BUS_ID}, {name: TRANSFORMERS_CACHE, value: ./cache/}, {name: WANDB_PROJECT,
          value: open-instruct}, {name: WANDB_WATCH, value: false}, {name: WANDB_LOG_MODEL,
          value: false}, {name: WANDB_DISABLED, value: true}, {name: OPENAI_API_KEY,
          secret: openai_api_key}], image: {beaker: hamishivi/open-instruct}, name: open_instruct_eval_toxigen_test_tulu_7b_01262024,
      resources: {gpuCount: 1}, result: {path: /output}}], version: v2}
